# Towards Robust Audio Deepfake Detection: An Evolving Benchmark for Continual Learning

This repository hosts the official project of the paper ["Towards Robust Audio Deepfake Detection: An Evolving Benchmark for Continual Learning"](https://arxiv.org/abs/2405.08596)!

Test your deepfake audio detection modelâ€™s continual learning ability using our benchmark, which supports various state-of-the-art methods.

## ğŸš€ Quick Start

### Step 1: Set up the environment
```bash
conda create -n cl_fad --python=3.8
pip install -r requirement.txt
```
### Step 2: Configure your experiment Create a configuration file `config.yaml` or use the provided template located at `yaml/fad_feature.yaml`.

### Step 3: Train your model Run the following command to start training: 
```bash
bash train.sh
```
ğŸ—“ï¸ Project Timeline --------------------
### 2024.05.08 
* ğŸ¯ Added the **Equal Error Rate (EER)** metric to the benchmark. 
* ğŸš€ To start training, simply run: 
```bash 
bash train.sh
```
### 2024.07.21 
* âœ… Most methods can run normally. 
* ğŸ” Currently debugging the **ELMA**
### 2024.08.13
* âœ¨ Major modifications to the original benchmark: It is now clearer and faster.
* ğŸ”§ Currently running 8 experiments.
* ğŸ” Continued debugging of ELMA.
### 2024.09.14
* ğŸ‰ Successfully completed debugging of ELMA, which now shows great results!